import os
import time
import json
import random
import requests
import warnings
import unicodedata
import urllib.parse
from io import BytesIO
from PIL import Image
from dotenv import load_dotenv

# Suppression des avertissements de d√©pr√©ciation (Gemini)
warnings.filterwarnings("ignore", category=FutureWarning, module="google.generativeai")

# --- Librairies Externes ---
import firebase_admin
from firebase_admin import credentials, firestore
import google.generativeai as genai
from playwright.sync_api import sync_playwright

# Chargement des variables d'environnement (.env)
load_dotenv()

# --- CONFIGURATION ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
FACEBOOK_ACCESS_TOKEN = os.getenv("FACEBOOK_ACCESS_TOKEN")
FIREBASE_KEY_PATH = "serviceAccountKey.json"  # Doit √™tre √† la racine du projet
PROMPT_INSTRUCTION = "Evalue cette guitare Au quebec (avec le prix)."  # Instruction principale pour l'analyse IA

# ==================================================================================
# ‚ö†Ô∏è IMPORTANT : CES IDs DOIVENT CORRESPONDRE √Ä CEUX DE VOTRE APP REACT ‚ö†Ô∏è
# Regardez dans l'en-t√™te de l'application React ou dans la section "V√©rification du chemin Python"
# ==================================================================================
APP_ID_TARGET = "c_5d118e719dbddbfc_index.html-217"  # √Ä remplacer par l'App ID affich√© dans React
USER_ID_TARGET = "00737242777130596039"           # √Ä remplacer par le User ID affich√© dans React
# ==================================================================================

# Initialisation Gemini
model = None
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.0-flash')
else:
    print("‚ö†Ô∏è ATTENTION: Pas de cl√© API Gemini trouv√©e dans le fichier .env")

# Initialisation Firebase
db = None
offline_mode = False

if not firebase_admin._apps:
    try:
        if os.path.exists(FIREBASE_KEY_PATH):
            cred = credentials.Certificate(FIREBASE_KEY_PATH)
            print(f"üîë Projet ID d√©tect√© : {cred.project_id}")
            firebase_admin.initialize_app(cred)
            db = firestore.client()
            print("‚úÖ Firebase connect√© avec succ√®s (Database: Default).")
            
            # Test de permissions imm√©diat
            try:
                list(db.collections())
                print("‚úÖ Permissions de lecture confirm√©es sur la base.")
            except Exception as e:
                print(f"‚ùå ERREUR PERMISSIONS : {e}")
                print("üëâ Le compte de service n'a pas les droits. Passage en MODE HORS-LIGNE (Simulation).")
                offline_mode = True
        else:
            print(f"‚ö†Ô∏è Fichier {FIREBASE_KEY_PATH} introuvable. Passage en MODE HORS-LIGNE.")
            offline_mode = True

    except Exception as e:
        print(f"‚ùå Erreur critique Firebase: {e}")
        offline_mode = True


class GuitarHunterBot:
    def __init__(self, prompt_instruction=PROMPT_INSTRUCTION):
        global offline_mode
        self.prompt_instruction = prompt_instruction
        # Configuration par d√©faut
        self.scan_config = {
            "max_ads": 5,
            "frequency": 60, # minutes
            "location": "montreal",
            "distance": 60, # km
            "min_price": 0,
            "max_price": 10000,
            "search_query": "electric guitar"
        }
        self.last_refresh_timestamp = 0
        self.city_mapping = {} # Sera rempli depuis Firestore

        # Construction du chemin pour v√©rification
        self.collection_path = f"artifacts/{APP_ID_TARGET}/users/{USER_ID_TARGET}/guitar_deals"
        
        print(f"\nüîß CONFIGURATION DU BOT :")
        print(f"   - APP ID  : {APP_ID_TARGET}")
        print(f"   - USER ID : {USER_ID_TARGET}")
        print(f"   - CHEMIN  : {self.collection_path}")
        print(f"   - PROMPT  : {self.prompt_instruction}")
        
        if offline_mode:
            print("‚ö†Ô∏è ATTENTION : MODE HORS-LIGNE ACTIV√â. Aucune donn√©e ne sera sauvegard√©e dans Firebase.")
            return

        # R√©f√©rence √† la collection sp√©cifique suivie par l'App React
        self.collection_ref = db.collection('artifacts').document(APP_ID_TARGET) \
            .collection('users').document(USER_ID_TARGET) \
            .collection('guitar_deals')
            
        # R√©f√©rence au document utilisateur pour √©couter les changements de prompt et config
        self.user_ref = db.collection('artifacts').document(APP_ID_TARGET) \
            .collection('users').document(USER_ID_TARGET)
            
        # R√©f√©rence √† la collection des villes
        self.cities_ref = db.collection('artifacts').document(APP_ID_TARGET) \
            .collection('users').document(USER_ID_TARGET) \
            .collection('cities')

        # --- CORRECTION : CR√âATION EXPLICITE DES PARENTS (Pour √©viter l'italique/fant√¥me) ---
        print("   ‚è≥ V√©rification de l'acc√®s Firestore (Timeout 10s)...")
        try:
            # 1. Cr√©ation du document App (artifacts/{APP_ID})
            app_ref = db.collection('artifacts').document(APP_ID_TARGET)
            
            # V√©rification de la connexion avant de tenter des √©critures
            try:
                # Ajout d'un timeout pour √©viter le blocage infini si le r√©seau/auth d√©conne
                doc_snapshot = app_ref.get(timeout=10)
                
                if not doc_snapshot.exists:
                    app_ref.set({'created_at': firestore.SERVER_TIMESTAMP, 'type': 'app_root'})
                    print(f"üìÅ Document parent cr√©√© : artifacts/{APP_ID_TARGET}")
                else:
                    print("   ‚úÖ Connexion Firestore OK.")
                    
            except Exception as e:
                print(f"‚ùå Erreur de connexion Firebase lors de l'init : {e}")
                print("üëâ Passage en MODE HORS-LIGNE temporaire.")
                offline_mode = True
                return

            # 2. Cr√©ation du document User (artifacts/{APP_ID}/users/{USER_ID})
            user_ref = app_ref.collection('users').document(USER_ID_TARGET)
            if not user_ref.get(timeout=10).exists:
                user_ref.set({
                    'created_at': firestore.SERVER_TIMESTAMP, 
                    'type': 'user_root', 
                    'prompt': self.prompt_instruction,
                    'scanConfig': self.scan_config
                })
                print(f"üë§ Document parent cr√©√© : users/{USER_ID_TARGET}")
            else:
                # Si le document existe, on r√©cup√®re le prompt et la config
                self.sync_configuration(initial=True)
                
            # Chargement initial des villes
            self.load_cities_from_firestore()
                
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible de cr√©er les documents parents (non bloquant) : {e}")

    def load_cities_from_firestore(self):
        """Charge la liste des villes configur√©es par l'utilisateur depuis Firestore."""
        if offline_mode:
            return

        try:
            docs = self.cities_ref.stream()
            new_mapping = {}
            count = 0
            for doc in docs:
                data = doc.to_dict()
                if 'name' in data and 'id' in data:
                    # Normalisation du nom pour la recherche (minuscules, sans accents)
                    normalized_name = data['name'].lower().strip()
                    normalized_name = unicodedata.normalize('NFD', normalized_name).encode('ascii', 'ignore').decode("utf-8")
                    new_mapping[normalized_name] = data['id']
                    count += 1
            
            self.city_mapping = new_mapping
            print(f"   üèôÔ∏è {count} villes charg√©es depuis Firestore.")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur chargement des villes : {e}")

    def sync_configuration(self, initial=False):
        """Synchronise la configuration et v√©rifie les demandes de refresh."""
        if offline_mode:
            return False

        try:
            # On recharge aussi les villes √† chaque sync pour √™tre √† jour
            if not initial:
                self.load_cities_from_firestore()

            doc = self.user_ref.get()
            if doc.exists:
                data = doc.to_dict()
                
                # 1. Prompt
                if 'prompt' in data and data['prompt'] != self.prompt_instruction:
                    self.prompt_instruction = data['prompt']
                    print(f"üîÑ Prompt mis √† jour : {self.prompt_instruction}")

                # 2. Scan Config
                if 'scanConfig' in data:
                    config = data['scanConfig']
                    self.scan_config['max_ads'] = config.get('maxAds', 5)
                    self.scan_config['frequency'] = config.get('frequency', 60)
                    self.scan_config['location'] = config.get('location', 'montreal')
                    self.scan_config['distance'] = config.get('distance', 60)
                    self.scan_config['min_price'] = config.get('minPrice', 0)
                    self.scan_config['max_price'] = config.get('maxPrice', 10000)
                    self.scan_config['search_query'] = config.get('searchQuery', 'electric guitar')
                    # print(f"‚öôÔ∏è Config charg√©e : {self.scan_config}")

                # 3. Force Refresh
                if 'forceRefresh' in data:
                    last_refresh = data['forceRefresh']
                    # print(f"DEBUG: Firestore timestamp: {last_refresh}, Bot timestamp: {self.last_refresh_timestamp}")
                    
                    if initial:
                        # Initialisation : on se cale sur le timestamp actuel sans d√©clencher
                        self.last_refresh_timestamp = last_refresh
                    elif last_refresh != self.last_refresh_timestamp:
                        print(f"‚ö° Refresh manuel demand√© ! (Timestamp: {last_refresh})")
                        self.last_refresh_timestamp = last_refresh
                        return True # Signal to run scan immediately
            
            return False
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sync config : {e}")
            return False

    def extract_facebook_id(self, url):
        """Extrait l'ID num√©rique unique de l'annonce Facebook depuis l'URL."""
        try:
            # Format typique: https://www.facebook.com/marketplace/item/1234567890/
            if "/item/" in url:
                # On coupe apr√®s /item/
                segment = url.split("/item/")[1]
                # On prend ce qu'il y a avant le prochain / ou ?
                fb_id = segment.split("/")[0].split("?")[0]
                if fb_id.isdigit():
                    return fb_id
            return None
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur extraction ID: {e}")
            return None

    def download_image(self, url):
        """T√©l√©charge l'image depuis l'URL et la convertit en objet PIL Image."""
        try:
            if not url or "via.placeholder.com" in url:
                return None
            
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                return Image.open(BytesIO(response.content))
            return None
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible de t√©l√©charger l'image : {e}")
            return None

    def analyze_deal_with_gemini(self, listing_data):
        """Utilise Gemini pour √©valuer si l'annonce est une bonne affaire (Multimodal)."""
        # Mise √† jour du prompt avant chaque analyse (au cas o√π)
        self.sync_configuration()

        if not model:
             print("‚ö†Ô∏è Mod√®le Gemini non initialis√© (Cl√© API manquante ?)")
             return {
                "verdict": "FAIR",
                "estimated_value": listing_data['price'],
                "reasoning": "Analyse IA impossible : Mod√®le non initialis√©.",
                "confidence": 0
            }

        print(f"ü§ñ Analyse IA pour : {listing_data['title']}...")

        # T√©l√©chargement des images
        images = []
        # Gestion de plusieurs images (imageUrls) ou d'une seule (imageUrl)
        urls_to_process = listing_data.get('imageUrls', [])
        if not urls_to_process and listing_data.get('imageUrl'):
            urls_to_process = [listing_data['imageUrl']]
            
        # Limite √† 5 images pour √©viter de surcharger
        urls_to_process = urls_to_process[:5]

        for url in urls_to_process:
            img = self.download_image(url)
            if img:
                images.append(img)
        
        prompt_text = f"""
        {self.prompt_instruction}
        
        D√©tails de l'annonce :
        Titre: {listing_data['title']}
        Prix: {listing_data['price']} $
        Description: {listing_data['description']}

        R√®gles strictes pour le verdict :
        - "GOOD_DEAL" : Le prix demand√© est INFERIEUR √† la valeur estim√©e.
        - "FAIR" : Le prix demand√© est PROCHE de la valeur estim√©e (√† +/- 10%).
        - "BAD_DEAL" : Le prix demand√© est SUPERIEUR √† la valeur estim√©e.

        R√©ponds en JSON uniquement avec cette structure :
        {{
          "verdict": "GOOD_DEAL" | "FAIR" | "BAD_DEAL",
          "estimated_value": number,
          "reasoning": "explication d√©taill√©e et compl√®te justifiant le verdict par rapport au prix et √† la valeur",
          "confidence": number (0-100)
        }}
        """

        try:
            # Construction du contenu multimodal
            content = [prompt_text]
            content.extend(images)
            
            if images:
                print(f"   üì∏ {len(images)} images incluses dans l'analyse.")
            else:
                print("   ‚ö†Ô∏è Analyse texte uniquement (pas d'image valide).")

            response = model.generate_content(content)
            clean_text = response.text.replace('```json', '').replace('```', '').strip()
            return json.loads(clean_text)
        except Exception as e:
            error_str = str(e)
            if "403" in error_str and "leaked" in error_str:
                print("\n" + "!"*60)
                print("‚ùå ERREUR CRITIQUE : VOTRE CL√â API GEMINI A FUIT√â ET EST BLOQU√âE.")
                print("üëâ Google a d√©sactiv√© cette cl√© par s√©curit√©.")
                print("üëâ G√©n√©rez-en une nouvelle ici : https://aistudio.google.com/app/apikey")
                print("üëâ Mettez √† jour GEMINI_API_KEY dans votre fichier .env")
                print("!"*60 + "\n")
            else:
                print(f"‚ùå Erreur Gemini: {e}")

            return {
                "verdict": "FAIR",
                "estimated_value": listing_data['price'],
                "reasoning": "Erreur d'analyse IA (Voir logs console)",
                "confidence": 0
            }

    def save_to_firestore(self, listing_data, analysis, doc_id=None):
        """Sauvegarde les donn√©es au chemin exact √©cout√© par React."""
        if offline_mode:
            print(f"üö´ [OFFLINE] Donn√©es non sauvegard√©es : {listing_data['title']}")
            return

        try:
            # Si pas d'ID fourni, on g√©n√®re un ID de secours (ne devrait pas arriver avec FB)
            if not doc_id:
                doc_id = f"{listing_data['title'][:15]}_{listing_data['price']}".replace(" ", "_").lower()
                doc_id = "".join(c for c in doc_id if c.isalnum() or c in ('_', '-'))

            data = {
                **listing_data,
                "aiAnalysis": analysis,
                "timestamp": firestore.SERVER_TIMESTAMP,
                "status": "analyzed"
            }

            self.collection_ref.document(doc_id).set(data)
            print(f"üíæ Envoy√© √† l'App: {listing_data['title']} (ID: {doc_id})")
        except Exception as e:
            print(f"‚ùå Erreur Firestore: {e}")

    def scan_facebook_marketplace(self, search_query="electric guitar", location="montreal", distance=60, min_price=0, max_price=10000, max_ads=5):
        """Scrape r√©ellement Facebook Marketplace avec Playwright."""
        print(f"\nüåç Lancement du scan Facebook pour '{search_query}' √† {location} (Max: {max_ads}, Prix: {min_price}-{max_price}$)...")
        
        # --- VALIDATION DE LA VILLE VIA FIRESTORE ---
        normalized_loc = location.lower().strip()
        # Nettoyage des accents (ex: Montr√©al -> montreal)
        normalized_loc = unicodedata.normalize('NFD', normalized_loc).encode('ascii', 'ignore').decode("utf-8")
        
        city_id = self.city_mapping.get(normalized_loc)
        
        if not city_id:
            # Si c'est d√©j√† un ID (chiffres), on laisse passer
            if location.isdigit():
                city_id = location
            else:
                error_msg = f"Ville '{location}' inconnue. Ajoutez-la dans l'onglet Configuration."
                print(f"‚ùå {error_msg}")
                
                # Envoi de l'erreur √† l'UI via Firestore
                if not offline_mode:
                    try:
                        self.user_ref.update({'scanStatus': 'error', 'scanError': error_msg})
                    except Exception as e:
                        print(f"‚ö†Ô∏è Impossible d'envoyer l'erreur √† l'UI : {e}")
                return # On arr√™te le scan ici
        
        # Si on a trouv√© la ville, on efface les erreurs pr√©c√©dentes
        if not offline_mode:
            try:
                self.user_ref.update({'scanStatus': 'running', 'scanError': firestore.DELETE_FIELD})
            except:
                pass

        print(f"   üìç Ville identifi√©e : ID {city_id}")

        with sync_playwright() as p:

            # --- MODIFICATION : D√©marrage minimis√© ---
            # args=["--start-minimized"] demande √† Chrome de d√©marrer r√©duit dans la barre des t√¢ches
            browser = p.chromium.launch(
                headless=False,
                args=["--start-minimized"] 
            )
            
            # Coordonn√©es de Montr√©al pour forcer la g√©olocalisation
            # Cela aide Facebook √† centrer la carte au bon endroit
            montreal_geo = {"latitude": 45.5017, "longitude": -73.5673}

            # Configuration du contexte
            # viewport=None est CRUCIAL pour que --start-minimized fonctionne (sinon Playwright redimensionne la fen√™tre)
            context = browser.new_context(
                viewport=None,
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
                locale="fr-CA",
                timezone_id="America/Montreal",
                geolocation=montreal_geo,
                permissions=["geolocation"]
            )
            
            page = context.new_page()
            
            # Encodage de la requ√™te de recherche pour l'URL
            encoded_query = urllib.parse.quote(search_query)
            
            # URL de recherche Marketplace avec l'ID de ville
            url = f"https://www.facebook.com/marketplace/{city_id}/search/?minPrice={min_price}&maxPrice={max_price}&query={encoded_query}&exact=false&radius_in_km={distance}"
            
            try:
                print(f"   ‚û°Ô∏è Navigation vers : {url}")
                print(f"   üîó URL g√©n√©r√©e : {url}")
                page.goto(url, timeout=60000)
                
                # Gestion des popups cookies (Europe/Canada)
                try:
                    # S√©lecteurs g√©n√©riques pour les boutons de cookies
                    page.get_by_role("button", name="Allow all cookies").click(timeout=3000)
                    print("   üç™ Cookies accept√©s.")
                except:
                    pass
                
                try:
                    page.get_by_role("button", name="Decline optional cookies").click(timeout=3000)
                    print("   üç™ Cookies optionnels refus√©s.")
                except:
                    pass

                # Attente du chargement de la grille de r√©sultats
                # On attend un √©l√©ment qui ressemble √† une annonce ou le conteneur principal
                try:
                    page.wait_for_selector("div[role='main']", timeout=15000)
                except:
                    print("‚ö†Ô∏è Timeout en attendant le contenu principal. La page a peut-√™tre chang√©.")

                # Scroll progressif pour charger plus d'annonces (lazy loading)
                print("   üìú D√©filement pour charger les annonces...")
                for _ in range(3):
                    page.mouse.wheel(0, 1000)
                    time.sleep(2)

                # Extraction des liens d'annonces
                # Les annonces Marketplace ont g√©n√©ralement des liens contenant '/marketplace/item/'
                print("   üîç Recherche des √©l√©ments d'annonce...")
                listings_locators = page.locator("a[href*='/marketplace/item/']").all()
                
                print(f"   üëÄ {len(listings_locators)} √©l√©ments trouv√©s (certains peuvent √™tre des doublons).")
                
                processed_count = 0
                seen_urls = set()

                for link_loc in listings_locators:
                    if processed_count >= max_ads: 
                        print(f"   üõë Limite de {max_ads} annonces atteinte.")
                        break
                        
                    href = link_loc.get_attribute("href")
                    if not href:
                        continue
                        
                    # Nettoyage de l'URL (parfois relative)
                    if href.startswith("/"):
                        full_link = f"https://www.facebook.com{href}"
                    else:
                        full_link = href
                        
                    # On retire les param√®tres de tracking FB pour l'unicit√©
                    clean_link = full_link.split('?')[0]
                    
                    if clean_link in seen_urls:
                        continue
                    seen_urls.add(clean_link)

                    # --- Extraction des ID Facebook ---
                    fb_id = self.extract_facebook_id(clean_link)
                    if not fb_id:
                        continue

                    # --- Extraction des donn√©es brutes ---
                    text_content = link_loc.inner_text()
                    lines = [line.strip() for line in text_content.split('\n') if line.strip()]
                    
                    # Extraction de l'image (miniature)
                    img_loc = link_loc.locator("img").first
                    image_url = "https://via.placeholder.com/400?text=No+Image"
                    
                    # --- MODIFICATION : Extraction du titre via l'attribut ALT de l'image ---
                    # C'est beaucoup plus fiable que de deviner dans le texte
                    title = ""
                    if img_loc.count() > 0:
                        src = img_loc.get_attribute("src")
                        if src:
                            image_url = src
                        
                        # Le titre complet est souvent dans le alt de l'image
                        alt_text = img_loc.get_attribute("alt")
                        if alt_text and len(alt_text) > 3:
                            title = alt_text

                    # Fallback si pas de alt text (rare)
                    if not title:
                        # On essaie de trouver une ligne qui n'est PAS un prix
                        for line in lines:
                            if not any(c in line for c in ['$', '‚Ç¨', '¬£', 'Free', 'Gratuit']) and len(line) > 3:
                                title = line
                                break
                        if not title:
                            title = "Titre Inconnu"

                    # Extraction du prix
                    price = 0
                    found_price = False
                    for line in lines:
                        if not found_price and any(c in line for c in ['$', '‚Ç¨', '¬£', 'Free', 'Gratuit']):
                            digits = ''.join(filter(str.isdigit, line))
                            if digits:
                                price = int(digits)
                                found_price = True
                            elif "Free" in line or "Gratuit" in line:
                                price = 0
                                found_price = True

                    # On ignore les annonces sans prix d√©tect√©
                    if (price > 0 or "Gratuit" in text_content or "Free" in text_content):
                        print(f"   ‚ú® Annonce trouv√©e : {title} ({price} $)")
                        
                        # --- VERIFICATION INTELLIGENTE (ID + PRIX) ---
                        if not offline_mode:
                            try:
                                doc_ref = self.collection_ref.document(fb_id)
                                doc_snap = doc_ref.get()
                                
                                if doc_snap.exists:
                                    existing_data = doc_snap.to_dict()
                                    old_price = existing_data.get('price')
                                    
                                    if old_price == price:
                                        print(f"   ‚è≠Ô∏è Annonce existante et prix inchang√© ({price} $). On passe.")
                                        continue
                                    else:
                                        print(f"   üîÑ Le prix a chang√© ! (Ancien: {old_price} $ -> Nouveau: {price} $). Mise √† jour...")
                            except Exception as e:
                                print(f"   ‚ö†Ô∏è Erreur v√©rification doublon (Firestore): {e}")
                        
                        # --- Scraping d√©taill√© de la page ---
                        description = f"Annonce Marketplace. {title}. Localisation: {location}"
                        image_urls = [] # Reset pour ne pas m√©langer avec la page pr√©c√©dente
                        
                        try:
                            print(f"   ‚û°Ô∏è  Ouverture de l'annonce pour d√©tails : {clean_link}")
                            detail_page = context.new_page()
                            detail_page.goto(clean_link, timeout=45000)
                            
                            # Attente du chargement
                            try:
                                detail_page.wait_for_selector("div[role='main']", timeout=10000)
                            except:
                                pass
                            time.sleep(2) 
                            
                            # --- RECUPERATION DES IMAGES (Mode Galerie) ---
                            collected_urls = []
                            
                            # S√©lecteur pour le bouton "Suivant" (Fl√®che droite)
                            next_btn_selector = "div[aria-label*='suivante'], div[aria-label*='Next'], div[aria-label*='Suivant']"
                            
                            # On tente de faire d√©filer jusqu'√† 10 images
                            for i in range(10):
                                # 1. Capturer l'image principale visible
                                try:
                                    # On cible les images dans le main role pour √©viter les pubs/suggestions
                                    imgs = detail_page.locator("div[role='main'] img").all()
                                    
                                    for img in imgs:
                                        if not img.is_visible(): continue
                                        
                                        box = img.bounding_box()
                                        # Filtre taille : on veut la grande image (souvent > 300px)
                                        if box and box['width'] > 300 and box['height'] > 300:
                                            src = img.get_attribute("src")
                                            if src and "scontent" in src and src not in collected_urls:
                                                collected_urls.append(src)
                                                # On a trouv√© l'image principale affich√©e, on arr√™te de chercher dans les autres img de la page pour ce step
                                                break 
                                except Exception as e:
                                    pass

                                # 2. Cliquer sur "Suivant"
                                try:
                                    btn = detail_page.locator(next_btn_selector).first
                                    if btn.count() > 0 and btn.is_visible():
                                        btn.click(timeout=1000)
                                        time.sleep(1) # Pause pour le chargement de la nouvelle image
                                    else:
                                        break
                                except:
                                    break
                            
                            image_urls = collected_urls
                            print(f"   üì∏ {len(image_urls)} images r√©cup√©r√©es via d√©filement.")
                            
                            # --- RECUPERATION DESCRIPTION ---
                            try:
                                detail_page.get_by_role("button", name="Plus").click(timeout=1000)
                            except:
                                try:
                                    detail_page.get_by_role("button", name="See more").click(timeout=1000)
                                except:
                                    pass
                                
                            full_text = detail_page.locator("body").inner_text()
                            description = full_text[:3000]

                            detail_page.close()
                        except Exception as e:
                            print(f"   ‚ö†Ô∏è Impossible de r√©cup√©rer les d√©tails (fallback) : {e}")
                            if 'detail_page' in locals():
                                try: detail_page.close()
                                except: pass

                        # Si aucune image trouv√©e dans l'annonce, on met une liste vide (ou placeholder g√©n√©rique), 
                        # mais PAS l'image de la recherche (image_url) comme demand√©.
                        final_image_url = image_urls[0] if image_urls else "https://via.placeholder.com/400?text=No+Image+Found"

                        listing_data = {
                            "title": title,
                            "price": price,
                            "description": description,
                            "imageUrl": final_image_url,
                            "imageUrls": image_urls,
                            "link": clean_link,
                            "location": location,
                            "searchDistance": distance
                        }
                        
                        # Analyse IA
                        analysis = self.analyze_deal_with_gemini(listing_data)
                        
                        # Sauvegarde avec l'ID Facebook
                        self.save_to_firestore(listing_data, analysis, doc_id=fb_id)
                        
                        processed_count += 1
                        
            except Exception as e:
                print(f"‚ùå Erreur durant le scraping : {e}")
                import traceback
                traceback.print_exc()
            finally:
                browser.close()
                print("üèÅ Session de scraping termin√©e.")

    def run_test_scan(self):
        """G√©n√®re des donn√©es de test pour v√©rifier la synchronisation."""
        print(f"üîé D√©marrage du scan de test (MOCK)...")

        mock_listings = [
            {
                "title": "Gibson Les Paul Standard 2021",
                "price": 1600,
                "description": "√âtat neuf, micros Burstbucker, √©tui original. Urgent.",
                "imageUrl": "https://images.unsplash.com/photo-1516924962500-2b4b3b99ea02?q=80&w=400",
                "imageUrls": [
                    "https://images.unsplash.com/photo-1516924962500-2b4b3b99ea02?q=80&w=400",
                    "https://images.unsplash.com/photo-1564186763535-ebb21ef5277f?q=80&w=400"
                ],
                "link": "https://facebook.com/marketplace/item/1234567890"
            },
            {
                "title": "Squier Strat Classic Vibe 60s",
                "price": 250,
                "description": "Excellent √©tat, parfaite pour d√©buter ou upgrade.",
                "imageUrl": "https://images.unsplash.com/photo-1550291652-6ea9114a47b1?q=80&w=400",
                "imageUrls": [
                    "https://images.unsplash.com/photo-1550291652-6ea9114a47b1?q=80&w=400"
                ],
                "link": "https://facebook.com/marketplace/item/0987654321"
            }
        ]

        for listing in mock_listings:
            # Extraction ID fictif
            fb_id = self.extract_facebook_id(listing['link'])
            analysis = self.analyze_deal_with_gemini(listing)
            self.save_to_firestore(listing, analysis, doc_id=fb_id)
            time.sleep(1)


if __name__ == "__main__":
    # Demande du prompt personnalis√© au d√©marrage
    print(f"Prompt par d√©faut: {PROMPT_INSTRUCTION}")
    
    bot = GuitarHunterBot()
    
    print("\n--- MODE AUTOMATIQUE ---")
    print("Le bot va surveiller la configuration et scanner p√©riodiquement.")
    print("Appuyez sur Ctrl+C pour arr√™ter.")
    
    last_scan_time = 0
    
    try:
        while True:
            # 1. Synchronisation de la config et v√©rification du refresh manuel
            should_refresh = bot.sync_configuration()
            
            # 2. V√©rification du temps √©coul√©
            current_time = time.time()
            frequency_seconds = bot.scan_config['frequency'] * 60
            
            # Si refresh demand√© OU temps √©coul√©
            if should_refresh or (current_time - last_scan_time > frequency_seconds):
                if should_refresh:
                    print("‚ö° Lancement du scan (Manuel)...")
                else:
                    print(f"‚è∞ Lancement du scan (Auto - {bot.scan_config['frequency']} min)...")
                
                # Lancement du scan
                bot.scan_facebook_marketplace(
                    search_query=bot.scan_config['search_query'],
                    location=bot.scan_config['location'],
                    distance=bot.scan_config['distance'],
                    min_price=bot.scan_config['min_price'],
                    max_price=bot.scan_config['max_price'],
                    max_ads=bot.scan_config['max_ads']
                )
                
                last_scan_time = time.time()
                print(f"üí§ Prochain scan auto dans {bot.scan_config['frequency']} minutes...")
            
            # Pause courte pour √©viter de spammer Firestore
            time.sleep(5)
            
    except KeyboardInterrupt:
        print("\nüõë Arr√™t du bot.")