import os
import sys
import time
import json
import random
import requests
import warnings
import unicodedata
import urllib.parse
from io import BytesIO
from PIL import Image
from dotenv import load_dotenv

# Suppression des avertissements de d√©pr√©ciation (Gemini)
warnings.filterwarnings("ignore", category=FutureWarning, module="google.generativeai")

# --- Librairies Externes ---
import firebase_admin
from firebase_admin import credentials, firestore
import google.generativeai as genai
from playwright.sync_api import sync_playwright

# Chargement des variables d'environnement (.env)
load_dotenv()

# --- CONFIGURATION ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
FACEBOOK_ACCESS_TOKEN = os.getenv("FACEBOOK_ACCESS_TOKEN")
FIREBASE_KEY_PATH = "serviceAccountKey.json"  # Doit √™tre √† la racine du projet
PROMPT_INSTRUCTION = "Evalue cette guitare Au quebec (avec le prix)."  # Instruction principale pour l'analyse IA

# ==================================================================================
# ‚ö†Ô∏è IMPORTANT : CES IDs DOIVENT CORRESPONDRE √Ä CEUX DE VOTRE APP REACT ‚ö†Ô∏è
# Regardez dans l'en-t√™te de l'application React ou dans la section "V√©rification du chemin Python"
# ==================================================================================
APP_ID_TARGET = "c_5d118e719dbddbfc_index.html-217"  # √Ä remplacer par l'App ID affich√© dans React
USER_ID_TARGET = "00737242777130596039"           # √Ä remplacer par le User ID affich√© dans React
# ==================================================================================

# Initialisation Gemini
model = None
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.0-flash')
else:
    print("‚ö†Ô∏è ATTENTION: Pas de cl√© API Gemini trouv√©e dans le fichier .env")

# Initialisation Firebase
db = None
offline_mode = False

if not firebase_admin._apps:
    try:
        if os.path.exists(FIREBASE_KEY_PATH):
            cred = credentials.Certificate(FIREBASE_KEY_PATH)
            print(f"üîë Projet ID d√©tect√© : {cred.project_id}")
            firebase_admin.initialize_app(cred)
            db = firestore.client()
            print("‚úÖ Firebase connect√© avec succ√®s (Database: Default).")
            
            # Test de permissions imm√©diat
            try:
                list(db.collections())
                print("‚úÖ Permissions de lecture confirm√©es sur la base.")
            except Exception as e:
                print(f"‚ùå ERREUR PERMISSIONS : {e}")
                print("üëâ Le compte de service n'a pas les droits. Passage en MODE HORS-LIGNE (Simulation).")
                offline_mode = True
        else:
            print(f"‚ö†Ô∏è Fichier {FIREBASE_KEY_PATH} introuvable. Passage en MODE HORS-LIGNE.")
            offline_mode = True

    except Exception as e:
        print(f"‚ùå Erreur critique Firebase: {e}")
        offline_mode = True


class GuitarHunterBot:
    def __init__(self, prompt_instruction=PROMPT_INSTRUCTION):
        global offline_mode
        self.prompt_instruction = prompt_instruction
        # Configuration par d√©faut
        self.scan_config = {
            "max_ads": 5,
            "frequency": 60, # minutes
            "location": "montreal",
            "distance": 60, # km
            "min_price": 0,
            "max_price": 10000,
            "search_query": "electric guitar"
        }
        self.last_refresh_timestamp = 0
        self.city_mapping = {} # Sera rempli depuis Firestore

        # Construction du chemin pour v√©rification
        self.collection_path = f"artifacts/{APP_ID_TARGET}/users/{USER_ID_TARGET}/guitar_deals"
        
        print(f"\nüîß CONFIGURATION DU BOT :")
        print(f"   - APP ID  : {APP_ID_TARGET}")
        print(f"   - USER ID : {USER_ID_TARGET}")
        print(f"   - CHEMIN  : {self.collection_path}")
        print(f"   - PROMPT  : {self.prompt_instruction}")
        
        if offline_mode:
            print("‚ö†Ô∏è ATTENTION : MODE HORS-LIGNE ACTIV√â. Aucune donn√©e ne sera sauvegard√©e dans Firebase.")
            return

        # R√©f√©rence √† la collection sp√©cifique suivie par l'App React
        self.collection_ref = db.collection('artifacts').document(APP_ID_TARGET) \
            .collection('users').document(USER_ID_TARGET) \
            .collection('guitar_deals')
            
        # R√©f√©rence au document utilisateur pour √©couter les changements de prompt et config
        self.user_ref = db.collection('artifacts').document(APP_ID_TARGET) \
            .collection('users').document(USER_ID_TARGET)
            
        # R√©f√©rence √† la collection des villes
        self.cities_ref = db.collection('artifacts').document(APP_ID_TARGET) \
            .collection('users').document(USER_ID_TARGET) \
            .collection('cities')

        # --- CORRECTION : CR√âATION EXPLICITE DES PARENTS (Pour √©viter l'italique/fant√¥me) ---
        print("   ‚è≥ V√©rification de l'acc√®s Firestore (Timeout 10s)...")
        try:
            # 1. Cr√©ation du document App (artifacts/{APP_ID})
            app_ref = db.collection('artifacts').document(APP_ID_TARGET)
            
            # V√©rification de la connexion avant de tenter des √©critures
            try:
                # Ajout d'un timeout pour √©viter le blocage infini si le r√©seau/auth d√©conne
                doc_snapshot = app_ref.get(timeout=10)
                
                if not doc_snapshot.exists:
                    app_ref.set({'created_at': firestore.SERVER_TIMESTAMP, 'type': 'app_root'})
                    print(f"üìÅ Document parent cr√©√© : artifacts/{APP_ID_TARGET}")
                else:
                    print("   ‚úÖ Connexion Firestore OK.")
                    
            except Exception as e:
                print(f"‚ùå Erreur de connexion Firebase lors de l'init : {e}")
                print("üëâ Passage en MODE HORS-LIGNE temporaire.")
                offline_mode = True
                return

            # 2. Cr√©ation du document User (artifacts/{APP_ID}/users/{USER_ID})
            user_ref = app_ref.collection('users').document(USER_ID_TARGET)
            if not user_ref.get(timeout=10).exists:
                user_ref.set({
                    'created_at': firestore.SERVER_TIMESTAMP, 
                    'type': 'user_root', 
                    'prompt': self.prompt_instruction,
                    'scanConfig': self.scan_config
                })
                print(f"üë§ Document parent cr√©√© : users/{USER_ID_TARGET}")
            else:
                # Si le document existe, on r√©cup√®re le prompt et la config
                self.sync_configuration(initial=True)
                
            # Chargement initial des villes
            self.load_cities_from_firestore()
                
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible de cr√©er les documents parents (non bloquant) : {e}")

    def load_cities_from_firestore(self):
        """Charge la liste des villes configur√©es par l'utilisateur depuis Firestore."""
        if offline_mode:
            return

        try:
            docs = self.cities_ref.stream()
            new_mapping = {}
            count = 0
            for doc in docs:
                data = doc.to_dict()
                if 'name' in data and 'id' in data:
                    # Normalisation du nom pour la recherche (minuscules, sans accents)
                    normalized_name = data['name'].lower().strip()
                    normalized_name = unicodedata.normalize('NFD', normalized_name).encode('ascii', 'ignore').decode("utf-8")
                    new_mapping[normalized_name] = data['id']
                    count += 1
            
            self.city_mapping = new_mapping
            print(f"   üèôÔ∏è {count} villes charg√©es depuis Firestore.")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur chargement des villes : {e}")

    def sync_configuration(self, initial=False):
        """Synchronise la configuration et v√©rifie les demandes de refresh."""
        if offline_mode:
            return False

        try:
            # On recharge aussi les villes √† chaque sync pour √™tre √† jour
            if not initial:
                self.load_cities_from_firestore()

            doc = self.user_ref.get()
            if doc.exists:
                data = doc.to_dict()
                
                # 1. Prompt
                if 'prompt' in data and data['prompt'] != self.prompt_instruction:
                    self.prompt_instruction = data['prompt']
                    print(f"üîÑ Prompt mis √† jour : {self.prompt_instruction}")

                # 2. Scan Config
                if 'scanConfig' in data:
                    config = data['scanConfig']
                    self.scan_config['max_ads'] = config.get('maxAds', 5)
                    self.scan_config['frequency'] = config.get('frequency', 60)
                    self.scan_config['location'] = config.get('location', 'montreal')
                    self.scan_config['distance'] = config.get('distance', 60)
                    self.scan_config['min_price'] = config.get('minPrice', 0)
                    self.scan_config['max_price'] = config.get('maxPrice', 10000)
                    self.scan_config['search_query'] = config.get('searchQuery', 'electric guitar')
                    # print(f"‚öôÔ∏è Config charg√©e : {self.scan_config}")

                # 3. Force Refresh
                if 'forceRefresh' in data:
                    last_refresh = data['forceRefresh']
                    # print(f"DEBUG: Firestore timestamp: {last_refresh}, Bot timestamp: {self.last_refresh_timestamp}")
                    
                    if initial:
                        # Initialisation : on se cale sur le timestamp actuel sans d√©clencher
                        self.last_refresh_timestamp = last_refresh
                    elif last_refresh != self.last_refresh_timestamp:
                        print(f"‚ö° Refresh manuel demand√© ! (Timestamp: {last_refresh})")
                        self.last_refresh_timestamp = last_refresh
                        return True # Signal to run scan immediately
            
            return False
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sync config : {e}")
            return False

    def extract_facebook_id(self, url):
        """Extrait l'ID num√©rique unique de l'annonce Facebook depuis l'URL."""
        try:
            # Format typique: https://www.facebook.com/marketplace/item/1234567890/
            if "/item/" in url:
                # On coupe apr√®s /item/
                segment = url.split("/item/")[1]
                # On prend ce qu'il y a avant le prochain / ou ?
                fb_id = segment.split("/")[0].split("?")[0]
                if fb_id.isdigit():
                    return fb_id
            return None
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur extraction ID: {e}")
            return None

    def download_image(self, url):
        """T√©l√©charge l'image depuis l'URL et la convertit en objet PIL Image."""
        try:
            if not url or "via.placeholder.com" in url:
                return None
            
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                return Image.open(BytesIO(response.content))
            return None
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible de t√©l√©charger l'image : {e}")
            return None

    def analyze_deal_with_gemini(self, listing_data):
        """Utilise Gemini pour √©valuer si l'annonce est une bonne affaire (Multimodal)."""
        # Mise √† jour du prompt avant chaque analyse (au cas o√π)
        self.sync_configuration()

        if not model:
             print("‚ö†Ô∏è Mod√®le Gemini non initialis√© (Cl√© API manquante ?)")
             return {
                "verdict": "FAIR",
                "estimated_value": listing_data['price'],
                "reasoning": "Analyse IA impossible : Mod√®le non initialis√©.",
                "confidence": 0
            }

        print(f"ü§ñ Analyse IA pour : {listing_data['title']}...")

        # T√©l√©chargement des images
        images = []
        # Gestion de plusieurs images (imageUrls) ou d'une seule (imageUrl)
        urls_to_process = listing_data.get('imageUrls', [])
        if not urls_to_process and listing_data.get('imageUrl'):
            urls_to_process = [listing_data['imageUrl']]
            
        # Limite √† 5 images pour √©viter de surcharger
        urls_to_process = urls_to_process[:5]

        for url in urls_to_process:
            img = self.download_image(url)
            if img:
                images.append(img)
        
        prompt_text = f"""
        {self.prompt_instruction}
        
        D√©tails de l'annonce :
        Titre: {listing_data['title']}
        Prix: {listing_data['price']} $
        Description: {listing_data['description']}

        R√®gles strictes pour le verdict :
        - "GOOD_DEAL" : Le prix demand√© est INFERIEUR √† la valeur estim√©e.
        - "FAIR" : Le prix demand√© est PROCHE de la valeur estim√©e (√† +/- 10%).
        - "BAD_DEAL" : Le prix demand√© est SUPERIEUR √† la valeur estim√©e.

        R√©ponds en JSON uniquement avec cette structure :
        {{
          "verdict": "GOOD_DEAL" | "FAIR" | "BAD_DEAL",
          "estimated_value": number,
          "reasoning": "explication d√©taill√©e et compl√®te justifiant le verdict par rapport au prix et √† la valeur",
          "confidence": number (0-100)
        }}
        """

        try:
            # Construction du contenu multimodal
            content = [prompt_text]
            content.extend(images)
            
            if images:
                print(f"   üì∏ {len(images)} images incluses dans l'analyse.")
            else:
                print("   ‚ö†Ô∏è Analyse texte uniquement (pas d'image valide).")

            response = model.generate_content(content)
            clean_text = response.text.replace('```json', '').replace('```', '').strip()
            return json.loads(clean_text)
        except Exception as e:
            error_str = str(e)
            if "403" in error_str and "leaked" in error_str:
                print("\n" + "!"*60)
                print("‚ùå ERREUR CRITIQUE : VOTRE CL√â API GEMINI A FUIT√â ET EST BLOQU√âE.")
                print("üëâ Google a d√©sactiv√© cette cl√© par s√©curit√©.")
                print("üëâ G√©n√©rez-en une nouvelle ici : https://aistudio.google.com/app/apikey")
                print("üëâ Mettez √† jour GEMINI_API_KEY dans votre fichier .env")
                print("!"*60 + "\n")
            else:
                print(f"‚ùå Erreur Gemini: {e}")

            return {
                "verdict": "FAIR",
                "estimated_value": listing_data['price'],
                "reasoning": "Erreur d'analyse IA (Voir logs console)",
                "confidence": 0
            }

    def save_to_firestore(self, listing_data, analysis, doc_id=None):
        """Sauvegarde les donn√©es au chemin exact √©cout√© par React."""
        if offline_mode:
            print(f"üö´ [OFFLINE] Donn√©es non sauvegard√©es : {listing_data['title']}")
            return

        try:
            # Si pas d'ID fourni, on g√©n√®re un ID de secours (ne devrait pas arriver avec FB)
            if not doc_id:
                doc_id = f"{listing_data['title'][:15]}_{listing_data['price']}".replace(" ", "_").lower()
                doc_id = "".join(c for c in doc_id if c.isalnum() or c in ('_', '-'))

            data = {
                **listing_data,
                "aiAnalysis": analysis,
                "timestamp": firestore.SERVER_TIMESTAMP,
                "status": "analyzed"
            }

            self.collection_ref.document(doc_id).set(data)
            print(f"üíæ Envoy√© √† l'App: {listing_data['title']} (ID: {doc_id})")
        except Exception as e:
            print(f"‚ùå Erreur Firestore: {e}")

    def scan_facebook_marketplace(self, search_query="electric guitar", location="montreal", distance=60, min_price=0, max_price=10000, max_ads=5):
        """Scrape r√©ellement Facebook Marketplace avec Playwright."""
        print(f"\nüåç Lancement du scan Facebook pour '{search_query}' √† {location} (Max: {max_ads}, Prix: {min_price}-{max_price}$)...")
        
        # --- VALIDATION DE LA VILLE VIA FIRESTORE ---
        normalized_loc = location.lower().strip()
        # Nettoyage des accents (ex: Montr√©al -> montreal)
        normalized_loc = unicodedata.normalize('NFD', normalized_loc).encode('ascii', 'ignore').decode("utf-8")
        
        city_id = self.city_mapping.get(normalized_loc)
        
        if not city_id:
            # Si c'est d√©j√† un ID (chiffres), on laisse passer
            if location.isdigit():
                city_id = location
            else:
                error_msg = f"Ville '{location}' inconnue. Ajoutez-la dans l'onglet Configuration."
                print(f"‚ùå {error_msg}")
                
                # Envoi de l'erreur √† l'UI via Firestore
                if not offline_mode:
                    try:
                        self.user_ref.update({'scanStatus': 'error', 'scanError': error_msg})
                    except Exception as e:
                        print(f"‚ö†Ô∏è Impossible d'envoyer l'erreur √† l'UI : {e}")
                return # On arr√™te le scan ici
        
        # Si on a trouv√© la ville, on efface les erreurs pr√©c√©dentes
        if not offline_mode:
            try:
                self.user_ref.update({'scanStatus': 'running', 'scanError': firestore.DELETE_FIELD})
            except:
                pass

        print(f"   üìç Ville identifi√©e : ID {city_id}")

        with sync_playwright() as p:

            # --- MODIFICATION : D√©marrage minimis√© ---
            # args=["--start-minimized"] demande √† Chrome de d√©marrer r√©duit dans la barre des t√¢ches
            browser = p.chromium.launch(
                headless=False,
                args=["--start-minimized"] 
            )
            
            # Coordonn√©es de Montr√©al pour forcer la g√©olocalisation
            # Cela aide Facebook √† centrer la carte au bon endroit
            montreal_geo = {"latitude": 45.5017, "longitude": -73.5673}

            # Configuration du contexte
            # viewport=None est CRUCIAL pour que --start-minimized fonctionne (sinon Playwright redimensionne la fen√™tre)
            context = browser.new_context(
                viewport=None,
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
                locale="fr-CA",
                timezone_id="America/Montreal",
                geolocation=montreal_geo,
                permissions=["geolocation"]
            )
            
            page = context.new_page()
            
            # Encodage de la requ√™te de recherche pour l'URL
            encoded_query = urllib.parse.quote(search_query)
            
            # URL de recherche Marketplace avec l'ID de ville
            # On retire les param√®tres de rayon de l'URL pour laisser l'UI g√©rer
            url = f"https://www.facebook.com/marketplace/{city_id}/search/?minPrice={min_price}&maxPrice={max_price}&query={encoded_query}&exact=false"
            
            try:
                print(f"   ‚û°Ô∏è Navigation vers : {url}")
                print(f"   üîó URL g√©n√©r√©e : {url}")
                page.goto(url, timeout=60000)
                
                # --- ZOOM 50% (Demande utilisateur pour visibilit√© bouton) ---
                try:
                    print("   üîç Application du zoom 50%...")
                    page.evaluate("document.body.style.zoom = '0.5'")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Impossible d'appliquer le zoom : {e}")
                
                # Gestion des popups cookies (Europe/Canada)
                try:
                    # S√©lecteurs g√©n√©riques pour les boutons de cookies
                    page.get_by_role("button", name="Allow all cookies").click(timeout=3000)
                    print("   üç™ Cookies accept√©s.")
                except:
                    pass
                
                try:
                    page.get_by_role("button", name="Decline optional cookies").click(timeout=3000)
                    print("   üç™ Cookies optionnels refus√©s.")
                except:
                    pass

                # --- GESTION DU POPUP DE CONNEXION (NOUVEAU) ---
                try:
                    print("   üîê V√©rification du popup de connexion...")
                    time.sleep(2)
                    # S√©lecteur pour le bouton de fermeture (X) du popup de login
                    # Souvent un div avec role='button' et aria-label='Fermer' ou 'Close'
                    close_login_btn = page.locator("div[aria-label='Fermer'], div[aria-label='Close'], div[role='button'][aria-label*='Fermer']").first
                    
                    if close_login_btn.count() > 0 and close_login_btn.is_visible():
                        close_login_btn.click()
                        print("   ‚úÖ Popup de connexion ferm√©.")
                        time.sleep(1)
                    else:
                        # Parfois c'est juste un clic en dehors qui marche, ou le popup n'est pas l√†
                        pass
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erreur fermeture popup login (non bloquant) : {e}")


                # --- APPLICATION DU RAYON VIA UI (METHODE ROBUSTE) ---
                try:
                    print(f"   üìç Tentative d'application du rayon de {distance} km via l'interface...")
                    
                    # 1. Trouver le bouton de localisation (contient souvent "km" ou le nom de la ville)
                    # On attend que l'interface soit charg√©e
                    time.sleep(2)
                    
                    # S√©lecteur large pour le bouton de localisation dans la sidebar
                    loc_btn = page.locator("div[role='button']").filter(has_text="km").first
                    
                    if loc_btn.count() > 0 and loc_btn.is_visible():
                        loc_btn.click()
                        time.sleep(2) # Attente ouverture modale
                        
                        # 2. Trouver la modale et le menu d√©roulant du rayon
                        # On cible la modale active
                        modal = page.locator("div[role='dialog']").first
                        if modal.count() > 0:
                            print("   ‚úÖ Modale de localisation ouverte.")
                            
                            # Chercher le dropdown de rayon √† l'int√©rieur de la modale
                            # MISE A JOUR : Ciblage sp√©cifique bas√© sur le snippet fourni par l'utilisateur
                            # On cherche un √©l√©ment contenant "kilom√®tres" ou "km"
                            radius_dropdown = modal.locator("div, span").filter(has_text="kilom√®tres").last
                            
                            if radius_dropdown.count() == 0:
                                # Fallback sur "km" si "kilom√®tres" n'est pas trouv√©
                                radius_dropdown = modal.locator("div, span").filter(has_text="km").last
                            
                            if radius_dropdown.count() > 0:
                                print("   ‚úÖ Menu d√©roulant de rayon trouv√©.")
                                radius_dropdown.click()
                                
                                # 3. S√©lectionner l'option la plus proche
                                # On attend que les options apparaissent (souvent dans un portal global)
                                try:
                                    page.wait_for_selector("div[role='option']", timeout=5000)
                                except:
                                    print("   ‚ö†Ô∏è Timeout attente options.")

                                # On cherche les options globalement (au cas o√π ce serait un portal)
                                # On filtre pour ne garder que celles qui sont visibles
                                available_options = page.locator("div[role='option']").all()
                                
                                best_option = None
                                min_diff = float('inf')
                                best_text = ""
                                
                                # Filtrage manuel des options visibles
                                visible_options = []
                                for opt in available_options:
                                    if opt.is_visible():
                                        visible_options.append(opt)
                                
                                print(f"   ‚ÑπÔ∏è Analyse des {len(visible_options)} distances disponibles...")
                                
                                for option in visible_options:
                                    text = option.inner_text()
                                    # Extraction des chiffres uniquement
                                    digits = ''.join(filter(str.isdigit, text))
                                    
                                    if digits:
                                        val = int(digits)
                                        diff = abs(val - distance)
                                        
                                        # On cherche la diff√©rence minimale
                                        if diff < min_diff:
                                            min_diff = diff
                                            best_option = option
                                            best_text = text
                                
                                if best_option:
                                    print(f"   ‚úÖ Distance la plus proche trouv√©e : '{best_text}' (Delta: {min_diff} km)")
                                    best_option.click()
                                    time.sleep(1)
                                else:
                                    print(f"   ‚ö†Ô∏è Impossible de trouver une distance proche. Aucune option num√©rique d√©tect√©e.")
                                    
                            else:
                                print("   ‚ö†Ô∏è Menu d√©roulant de rayon NON trouv√© dans la modale.")
                            
                            # 4. Cliquer sur Appliquer dans la modale
                            # S√©lecteurs √©largis pour le bouton Appliquer
                            apply_btn = modal.locator("div[aria-label*='Appliquer'], div[aria-label*='Apply'], span:has-text('Appliquer'), span:has-text('Apply')").first
                            
                            if apply_btn.count() > 0:
                                print("   ‚úÖ Bouton 'Appliquer' trouv√©, clic...")
                                apply_btn.click()
                                
                                # Attente critique pour le rechargement des r√©sultats
                                time.sleep(5)
                                try:
                                    page.wait_for_load_state("networkidle", timeout=5000)
                                except:
                                    pass
                            else:
                                print("   ‚ö†Ô∏è Bouton 'Appliquer' introuvable.")
                                page.keyboard.press("Escape")
                                    
                        else:
                             print("   ‚ö†Ô∏è Modale de localisation non d√©tect√©e.")
                    else:
                        print("   ‚ö†Ô∏è Bouton de localisation introuvable dans l'interface.")

                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erreur lors de l'application du rayon (UI) : {e}")
                    # On continue quand m√™me, peut-√™tre que l'URL par d√©faut suffit

                # Attente du chargement de la grille de r√©sultats
                # On attend un √©l√©ment qui ressemble √† une annonce ou le conteneur principal
                try:
                    page.wait_for_selector("div[role='main']", timeout=15000)
                except:
                    print("‚ö†Ô∏è Timeout en attendant le contenu principal. La page a peut-√™tre chang√©.")

                # Scroll progressif pour charger plus d'annonces (lazy loading)
                print("   üìú D√©filement pour charger les annonces...")
                for _ in range(3):
                    page.mouse.wheel(0, 1000)
                    time.sleep(2)

                # Extraction des liens d'annonces
                # Les annonces Marketplace ont g√©n√©ralement des liens contenant '/marketplace/item/'
                print("   üîç Recherche des √©l√©ments d'annonce...")
                listings_locators = page.locator("a[href*='/marketplace/item/']").all()
                
                print(f"   üëÄ {len(listings_locators)} √©l√©ments trouv√©s (certains peuvent √™tre des doublons).")
                
                processed_count = 0
                seen_urls = set()

                for link_loc in listings_locators:
                    if processed_count >= max_ads: 
                        print(f"   üõë Limite de {max_ads} annonces atteinte.")
                        break
                        
                    href = link_loc.get_attribute("href")
                    if not href:
                        continue
                        
                    # Nettoyage de l'URL (parfois relative)
                    if href.startswith("/"):
                        full_link = f"https://www.facebook.com{href}"
                    else:
                        full_link = href
                        
                    # On retire les param√®tres de tracking FB pour l'unicit√©
                    clean_link = full_link.split('?')[0]
                    
                    if clean_link in seen_urls:
                        continue
                    seen_urls.add(clean_link)

                    # --- Extraction des ID Facebook ---
                    fb_id = self.extract_facebook_id(clean_link)
                    if not fb_id:
                        continue

                    # --- Extraction des donn√©es brutes ---
                    text_content = link_loc.inner_text()
                    lines = [line.strip() for line in text_content.split('\n') if line.strip()]
                    
                    # Extraction de l'image (miniature)
                    img_loc = link_loc.locator("img").first
                    image_url = "https://via.placeholder.com/400?text=No+Image"
                    
                    # --- MODIFICATION : Extraction du titre via l'attribut ALT de l'image ---
                    # C'est beaucoup plus fiable que de deviner dans le texte
                    title = ""
                    if img_loc.count() > 0:
                        src = img_loc.get_attribute("src")
                        if src:
                            image_url = src
                        
                        # Le titre complet est souvent dans le alt de l'image
                        alt_text = img_loc.get_attribute("alt")
                        if alt_text and len(alt_text) > 3:
                            title = alt_text

                    # Fallback si pas de alt text (rare)
                    if not title:
                        # On essaie de trouver une ligne qui n'est PAS un prix
                        for line in lines:
                            if not any(c in line for c in ['$', '‚Ç¨', '¬£', 'Free', 'Gratuit']) and len(line) > 3:
                                title = line
                                break
                        if not title:
                            title = "Titre Inconnu"

                    # Extraction du prix
                    price = 0
                    found_price = False
                    for line in lines:
                        if not found_price and any(c in line for c in ['$', '‚Ç¨', '¬£', 'Free', 'Gratuit']):
                            digits = ''.join(filter(str.isdigit, line))
                            if digits:
                                price = int(digits)
                                found_price = True
                            elif "Free" in line or "Gratuit" in line:
                                price = 0
                                found_price = True

                    # On ignore les annonces sans prix d√©tect√©
                    if (price > 0 or "Gratuit" in text_content or "Free" in text_content):
                        print(f"   ‚ú® Annonce trouv√©e : {title} ({price} $)")
                        
                        # --- VERIFICATION INTELLIGENTE (ID + PRIX) ---
                        if not offline_mode:
                            try:
                                doc_ref = self.collection_ref.document(fb_id)
                                doc_snap = doc_ref.get()
                                
                                if doc_snap.exists:
                                    existing_data = doc_snap.to_dict()
                                    old_price = existing_data.get('price')
                                    
                                    if old_price == price:
                                        print(f"   ‚è≠Ô∏è Annonce existante et prix inchang√© ({price} $). On passe.")
                                        continue
                                    else:
                                        print(f"   üîÑ Le prix a chang√© ! (Ancien: {old_price} $ -> Nouveau: {price} $). Mise √† jour...")
                            except Exception as e:
                                print(f"   ‚ö†Ô∏è Erreur v√©rification doublon (Firestore): {e}")
                        
                        # --- Scraping d√©taill√© de la page ---
                        description = f"Annonce Marketplace. {title}. Localisation: {location}" # Default description
                        image_urls = [] # Reset pour ne pas m√©langer avec la page pr√©c√©dente
                        
                        try:
                            print(f"   ‚û°Ô∏è  Ouverture de l'annonce pour d√©tails : {clean_link}")
                            detail_page = context.new_page()
                            detail_page.goto(clean_link, timeout=45000)
                            
                            # Attente du chargement
                            try:
                                detail_page.wait_for_selector("div[role='main']", timeout=10000)
                            except:
                                pass
                            time.sleep(2) 
                            
                            # --- RECUPERATION DES IMAGES (Mode Galerie) ---
                            collected_urls = []
                            
                            # S√©lecteur pour le bouton "Suivant" (Fl√®che droite) - Am√©lior√©
                            next_btn_selector = "div[aria-label*='suivante'], div[aria-label*='Next'], div[aria-label*='Suivant'], div[aria-label*='Photos suivantes']"
                            
                            # On tente de faire d√©filer jusqu'√† 10 images
                            for i in range(10):
                                # 1. Capturer l'image principale visible
                                try:
                                    # On cible les images dans le main role pour √©viter les pubs/suggestions
                                    imgs = detail_page.locator("div[role='main'] img").all()
                                    
                                    for img in imgs:
                                        if not img.is_visible(): continue
                                        
                                        box = img.bounding_box()
                                        # Filtre taille : on veut la grande image (souvent > 300px)
                                        if box and box['width'] > 300 and box['height'] > 300:
                                            src = img.get_attribute("src")
                                            if src and "scontent" in src and src not in collected_urls:
                                                collected_urls.append(src)
                                                # On a trouv√© l'image principale affich√©e, on arr√™te de chercher dans les autres img de la page pour ce step
                                                break 
                                except Exception as e:
                                    pass

                                # 2. Cliquer sur "Suivant" ou Fl√®che Droite
                                try:
                                    btn = detail_page.locator(next_btn_selector).first
                                    if btn.count() > 0 and btn.is_visible():
                                        btn.click(timeout=1000)
                                        time.sleep(1) # Pause pour le chargement de la nouvelle image
                                    else:
                                        # Fallback : Fl√®che droite clavier
                                        detail_page.keyboard.press("ArrowRight")
                                        time.sleep(1)
                                except:
                                    break
                            
                            # Si on n'a rien trouv√©, on essaie de prendre toutes les images visibles d'un coup (Grid view?)
                            if not collected_urls:
                                try:
                                    imgs = detail_page.locator("div[role='main'] img").all()
                                    for img in imgs:
                                        src = img.get_attribute("src")
                                        if src and "scontent" in src and src not in collected_urls:
                                            box = img.bounding_box()
                                            if box and box['width'] > 200: # Seuil plus bas
                                                collected_urls.append(src)
                                except: pass

                            image_urls = collected_urls
                            print(f"   üì∏ {len(image_urls)} images r√©cup√©r√©es.")
                            
                            # --- RECUPERATION DESCRIPTION (AM√âLIOR√âE ET FIABILIS√âE) ---
                            extracted_description = None
                            try:
                                # Tenter d'extraire de la balise meta og:description
                                og_description_meta = detail_page.locator('meta[property="og:description"]').get_attribute('content')
                                if og_description_meta and len(og_description_meta.strip()) > 10:
                                    extracted_description = og_description_meta.strip()
                                    print(f"   üìù Description extraite de og:description (longueur: {len(extracted_description)}).")
                                else:
                                    # Tenter d'extraire de la balise meta name="description"
                                    name_description_meta = detail_page.locator('meta[name="description"]').get_attribute('content')
                                    if name_description_meta and len(name_description_meta.strip()) > 10:
                                        extracted_description = name_description_meta.strip()
                                        print(f"   üìù Description extraite de meta name='description' (longueur: {len(extracted_description)}).")

                                if not extracted_description:
                                    # Fallback √† la m√©thode pr√©c√©dente si les meta tags ne donnent rien
                                    try:
                                        # Clic sur "Voir plus" pour d√©plier la description
                                        see_more_button = detail_page.locator('div[role="button"]:has-text("Voir plus"), div[role="button"]:has-text("See more")').first
                                        if see_more_button.is_visible(timeout=2000):
                                            see_more_button.click()
                                            time.sleep(0.5)

                                        # Strat√©gie 1: Chercher la section "D√©tails"
                                        details_heading = detail_page.locator('h2:has-text("D√©tails"), h2:has-text("Details")').first
                                        if details_heading.is_visible(timeout=1000):
                                            parent_container = details_heading.locator('xpath=..')
                                            all_texts = parent_container.locator('span[dir="auto"]').all_inner_texts()
                                            long_texts = [t.strip() for t in all_texts if len(t.strip()) > 50]
                                            if long_texts:
                                                extracted_description = max(long_texts, key=len)
                                                print(f"   üìù Description extraite via section 'D√©tails' (longueur: {len(extracted_description)}).")

                                        # Strat√©gie 2 (Fallback): Recherche globale dans 'main' si toujours rien
                                        if not extracted_description:
                                            print("   ‚ö†Ô∏è Section 'D√©tails' non trouv√©e ou vide, utilisation du fallback.")
                                            all_texts = detail_page.locator('div[role="main"] span[dir="auto"]').all_inner_texts()
                                            # Exclure le titre et le prix pour √©viter les faux positifs
                                            excluded_texts = {title, f"{price} $", location}
                                            long_texts = [t.strip() for t in all_texts if len(t.strip()) > 50 and t not in excluded_texts]
                                            if long_texts:
                                                extracted_description = max(long_texts, key=len)
                                                print(f"   üìù Description extraite via fallback (longueur: {len(extracted_description)}).")

                                    except Exception as fallback_e:
                                        print(f"   ‚ö†Ô∏è Erreur lors de l'extraction de la description via fallback: {fallback_e}")
                                        # La description par d√©faut sera utilis√©e

                            except Exception as meta_e:
                                print(f"   ‚ö†Ô∏è Erreur lors de l'extraction de la description via meta tags: {meta_e}")
                                # Continuer avec la logique de fallback si les meta tags √©chouent

                            if extracted_description:
                                description = extracted_description
                            else:
                                print("   ‚ö†Ô∏è Aucune description d√©taill√©e trouv√©e, utilisation de la description par d√©faut.")
                            
                            description = description[:3000] # Toujours tronquer pour la s√©curit√©

                            detail_page.close()
                        except Exception as e:
                            print(f"   ‚ùå Erreur lors de la r√©cup√©ration des d√©tails de l'annonce : {e}")
                            if 'detail_page' in locals():
                                try: detail_page.close()
                                except: pass

                        # Si aucune image trouv√©e dans l'annonce, on met une liste vide (ou placeholder g√©n√©rique), 
                        # mais PAS l'image de la recherche (image_url) comme demand√©.
                        final_image_url = image_urls[0] if image_urls else "https://via.placeholder.com/400?text=No+Image+Found"

                        listing_data = {
                            "title": title,
                            "price": price,
                            "description": description,
                            "imageUrl": final_image_url,
                            "imageUrls": image_urls,
                            "link": clean_link,
                            "location": location,
                            "searchDistance": distance
                        }
                        
                        # Analyse IA
                        analysis = self.analyze_deal_with_gemini(listing_data)
                        
                        # Sauvegarde avec l'ID Facebook
                        self.save_to_firestore(listing_data, analysis, doc_id=fb_id)
                        
                        processed_count += 1
                        
            except Exception as e:
                print(f"‚ùå Erreur durant le scraping : {e}")
                import traceback
                traceback.print_exc()
            finally:
                browser.close()
                print("üèÅ Session de scraping termin√©e.")

    def run_test_scan(self):
        """G√©n√®re des donn√©es de test pour v√©rifier la synchronisation."""
        print(f"üîé D√©marrage du scan de test (MOCK)...")

        mock_listings = [
            {
                "title": "Gibson Les Paul Standard 2021",
                "price": 1600,
                "description": "√âtat neuf, micros Burstbucker, √©tui original. Urgent.",
                "imageUrl": "https://images.unsplash.com/photo-1516924962500-2b4b3b99ea02?q=80&w=400",
                "imageUrls": [
                    "https://images.unsplash.com/photo-1516924962500-2b4b3b99ea02?q=80&w=400",
                    "https://images.unsplash.com/photo-1564186763535-ebb21ef5277f?q=80&w=400"
                ],
                "link": "https://facebook.com/marketplace/item/1234567890"
            },
            {
                "title": "Squier Strat Classic Vibe 60s",
                "price": 250,
                "description": "Excellent √©tat, parfaite pour d√©buter ou upgrade.",
                "imageUrl": "https://images.unsplash.com/photo-1550291652-6ea9114a47b1?q=80&w=400",
                "imageUrls": [
                    "https://images.unsplash.com/photo-1550291652-6ea9114a47b1?q=80&w=400"
                ],
                "link": "https://facebook.com/marketplace/item/0987654321"
            }
        ]

        for listing in mock_listings:
            # Extraction ID fictif
            fb_id = self.extract_facebook_id(listing['link'])
            analysis = self.analyze_deal_with_gemini(listing)
            self.save_to_firestore(listing, analysis, doc_id=fb_id)
            time.sleep(1)


if __name__ == "__main__":
    # Demande du prompt personnalis√© au d√©marrage
    print(f"Prompt par d√©faut: {PROMPT_INSTRUCTION}")
    
    bot = GuitarHunterBot()

    # --- S√âCURIT√â AU D√âMARRAGE ---
    if offline_mode:
        print("\n‚ùå Le bot n'a pas pu s'initialiser correctement (mode hors-ligne). Arr√™t du script.")
        sys.exit(1)
    
    print("\n--- MODE AUTOMATIQUE ---")
    print("Le bot va surveiller la configuration et scanner p√©riodiquement.")
    print("Appuyez sur Ctrl+C pour arr√™ter.")
    
    last_scan_time = 0
    
    try:
        while True:
            # 1. Synchronisation de la config et v√©rification du refresh manuel
            should_refresh = bot.sync_configuration()
            
            # 2. V√©rification du temps √©coul√©
            current_time = time.time()
            frequency_seconds = bot.scan_config['frequency'] * 60
            
            # Si refresh demand√© OU temps √©coul√©
            if should_refresh or (current_time - last_scan_time > frequency_seconds):
                if should_refresh:
                    print("‚ö° Lancement du scan (Manuel)...")
                else:
                    print(f"‚è∞ Lancement du scan (Auto - {bot.scan_config['frequency']} min)...")
                
                # Lancement du scan
                bot.scan_facebook_marketplace(
                    search_query=bot.scan_config['search_query'],
                    location=bot.scan_config['location'],
                    distance=bot.scan_config['distance'],
                    min_price=bot.scan_config['min_price'],
                    max_price=bot.scan_config['max_price'],
                    max_ads=bot.scan_config['max_ads']
                )
                
                last_scan_time = time.time()
                print(f"üí§ Prochain scan auto dans {bot.scan_config['frequency']} minutes...")
            
            # Pause courte pour √©viter de spammer Firestore
            time.sleep(5)
            
    except KeyboardInterrupt:
        print("\nüõë Arr√™t du bot.")